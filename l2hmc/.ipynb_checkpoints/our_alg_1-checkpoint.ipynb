{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import random\n",
    "import pdb\n",
    "# from multiprocessing import Process, Manager\n",
    "# from multiprocessing import set_start_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/home/nkotelevskii/github/corrected_l2hmc/l2hmc_pytorch/l2hmc/utils/')\n",
    "from func_utils_pt import acl_spectrum, ESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "# device = \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distributions_pt import Gaussian, GMM\n",
    "from layers_pt import Net\n",
    "from dynamics_pt import Dynamics\n",
    "from sampler_pt import propose\n",
    "from notebook_utils_pt import get_hmc_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dim = 2\n",
    "T = 5\n",
    "mu = np.zeros(2,)\n",
    "mu = torch.tensor(mu).to(device)\n",
    "cov = np.array([[50.05, -49.95], [-49.95, 50.05]])\n",
    "cov = torch.tensor(cov).to(device)\n",
    "\n",
    "mu_1 = np.array([-2., 0.])\n",
    "mu_2 = np.array([2., 0.])\n",
    "mus = np.array([mu_1, mu_2])\n",
    "cov_1 = 0.1 * np.eye(2)\n",
    "cov_2 = 0.1 * np.eye(2)\n",
    "covs = np.array([cov_1, cov_2])\n",
    "pis = np.array([0.5, 0.5])\n",
    "\n",
    "\n",
    "distribution = GMM(mus, covs, pis, device=device)\n",
    "# distribution = Gaussian(mu, cov, device=device)\n",
    "\n",
    "dynamics = Dynamics(x_dim, distribution.get_energy_function(), T=T, eps=0.1, net_factory=network, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "S = distribution.get_samples(500)\n",
    "plt.title('Strongly Correlated Gaussian (SCG)')\n",
    "plt.scatter(S[:, 0], S[:, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_batches = 5000\n",
    "n_samples = 300\n",
    "K = 10\n",
    "scale = torch.tensor(0.1, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoregressive_coeff_logit = nn.Parameter(torch.tensor(0., device=device, dtype=torch.float32))\n",
    "params = list(dynamics.parameters()) + list([autoregressive_coeff_logit])\n",
    "optim = Adam(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-10-8bc312febd33>(27)<module>()\n",
      "-> _, p_prop, log_alpha, z_new, log_jac = propose(x=z_old, dynamics=dynamics,\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-10-8bc312febd33>(28)<module>()\n",
      "-> init_v=p_new, do_mh_step=True, device=device, our_alg=True, use_barker=True)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> /home/nkotelevskii/github/corrected_l2hmc/l2hmc_pytorch/l2hmc/utils/sampler_pt.py(9)propose()\n",
      "-> def propose(x, dynamics, init_v=None, aux=None, do_mh_step=False, log_jac=False, temperature=None, device='cpu', our_alg=False, use_barker=False):\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/nkotelevskii/github/corrected_l2hmc/l2hmc_pytorch/l2hmc/utils/sampler_pt.py(10)propose()\n",
      "-> if dynamics.hmc:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/nkotelevskii/github/corrected_l2hmc/l2hmc_pytorch/l2hmc/utils/sampler_pt.py(15)propose()\n",
      "-> if temperature is not None:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/nkotelevskii/github/corrected_l2hmc/l2hmc_pytorch/l2hmc/utils/sampler_pt.py(17)propose()\n",
      "-> mask = (2 * torch.tensor(np.random.rand(x.shape[0], 1))).type(torch.int32).type(torchType).to(device)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/nkotelevskii/github/corrected_l2hmc/l2hmc_pytorch/l2hmc/utils/sampler_pt.py(19)propose()\n",
      "-> Lx1, Lv1, log_px1, log_jac_f = dynamics.forward(x.clone(), init_v=init_v, aux=aux, log_jac=log_jac, use_barker=use_barker)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/nkotelevskii/github/corrected_l2hmc/l2hmc_pytorch/l2hmc/utils/sampler_pt.py(20)propose()\n",
      "-> Lx2, Lv2, log_px2, log_jac_b = dynamics.backward(x.clone(), init_v=init_v, aux=aux, log_jac=log_jac, use_barker=use_barker)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/nkotelevskii/github/corrected_l2hmc/l2hmc_pytorch/l2hmc/utils/sampler_pt.py(26)propose()\n",
      "-> Lx = mask * Lx1 + (1 - mask) * Lx2  # by this we imitate the random choice of d (direction)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/nkotelevskii/github/corrected_l2hmc/l2hmc_pytorch/l2hmc/utils/sampler_pt.py(27)propose()\n",
      "-> Lv = mask * Lv1 + (1 - mask) * Lv2\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/nkotelevskii/github/corrected_l2hmc/l2hmc_pytorch/l2hmc/utils/sampler_pt.py(28)propose()\n",
      "-> log_jac = torch.squeeze(mask, dim=1) * log_jac_f + torch.squeeze((1 - mask), dim=1) * log_jac_b\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/nkotelevskii/github/corrected_l2hmc/l2hmc_pytorch/l2hmc/utils/sampler_pt.py(30)propose()\n",
      "-> if use_barker:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/nkotelevskii/github/corrected_l2hmc/l2hmc_pytorch/l2hmc/utils/sampler_pt.py(31)propose()\n",
      "-> log_px = []\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  log_jac.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([300])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  log_jac_f[:10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0850,  0.0225,  0.0497,  0.7350, -0.1303,  0.1816,  0.4727,  0.1170,\n",
      "         0.5956,  0.4069], device='cuda:0', grad_fn=<SliceBackward>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  log_jac_b[:10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5267, -0.1893, -0.3766, -0.5588, -0.7246, -0.2214,  0.0091,  0.0363,\n",
      "        -0.3706, -0.1027], device='cuda:0', grad_fn=<SliceBackward>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  mask[:10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  log_jac[:10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0850, -0.1893, -0.3766,  0.7350, -0.1303, -0.2214,  0.0091,  0.0363,\n",
      "        -0.3706, -0.1027], device='cuda:0', grad_fn=<SliceBackward>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  l\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 26  \t    Lx = mask * Lx1 + (1 - mask) * Lx2  # by this we imitate the random choice of d (direction)\n",
      " 27  \t    Lv = mask * Lv1 + (1 - mask) * Lv2\n",
      " 28  \t    log_jac = torch.squeeze(mask, dim=1) * log_jac_f + torch.squeeze((1 - mask), dim=1) * log_jac_b\n",
      " 29  \t\n",
      " 30  \t    if use_barker:\n",
      " 31  ->\t        log_px = []\n",
      " 32  \t        log_px.append(torch.squeeze(mask, dim=1) * log_px1[0] + torch.squeeze(1 - mask, dim=1) * log_px2[0])\n",
      " 33  \t        log_px.append(torch.squeeze(mask, dim=1) * log_px1[1] + torch.squeeze(1 - mask, dim=1) * log_px2[1])\n",
      " 34  \t    else:\n",
      " 35  \t        log_px = torch.squeeze(mask, dim=1) * log_px1 + torch.squeeze(1 - mask, dim=1) * log_px2\n",
      " 36  \t\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/nkotelevskii/github/corrected_l2hmc/l2hmc_pytorch/l2hmc/utils/sampler_pt.py(32)propose()\n",
      "-> log_px.append(torch.squeeze(mask, dim=1) * log_px1[0] + torch.squeeze(1 - mask, dim=1) * log_px2[0])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/nkotelevskii/github/corrected_l2hmc/l2hmc_pytorch/l2hmc/utils/sampler_pt.py(33)propose()\n",
      "-> log_px.append(torch.squeeze(mask, dim=1) * log_px1[1] + torch.squeeze(1 - mask, dim=1) * log_px2[1])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/nkotelevskii/github/corrected_l2hmc/l2hmc_pytorch/l2hmc/utils/sampler_pt.py(38)propose()\n",
      "-> outputs = []\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  log_px[0].shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([300])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  log_px[1].shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([300])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  log_px1[0][:10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-9.2153e+01, -9.4618e+01, -5.9847e+01, -3.8865e+01, -3.6416e+01,\n",
      "        -1.9663e+00, -9.9943e-01, -1.0300e-04, -3.4163e+01, -2.5716e+00],\n",
      "       device='cuda:0', grad_fn=<SliceBackward>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  log_px2[0][:10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-41.3271,  -6.9554, -96.6897, -94.7881,  -4.0268,  -0.1309,  -4.6488,\n",
      "         -6.2612, -87.0645,  -5.2690], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  log_px[0][:10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-92.1533,  -6.9554, -96.6897, -38.8652, -36.4158,  -0.1309,  -4.6488,\n",
      "         -6.2612, -87.0645,  -5.2690], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  l\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 33  \t        log_px.append(torch.squeeze(mask, dim=1) * log_px1[1] + torch.squeeze(1 - mask, dim=1) * log_px2[1])\n",
      " 34  \t    else:\n",
      " 35  \t        log_px = torch.squeeze(mask, dim=1) * log_px1 + torch.squeeze(1 - mask, dim=1) * log_px2\n",
      " 36  \t\n",
      " 37  \t\n",
      " 38  ->\t    outputs = []\n",
      " 39  \t\n",
      " 40  \t    if our_alg:\n",
      " 41  \t        if do_mh_step:\n",
      " 42  \t            new_Lx, new_log_px, new_log_jac = tf_accept(x=x, Lx=Lx, log_px=log_px, device=device,\n",
      " 43  \t                                                        our_alg=our_alg, use_barker=use_barker, log_jac=log_jac)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/nkotelevskii/github/corrected_l2hmc/l2hmc_pytorch/l2hmc/utils/sampler_pt.py(40)propose()\n",
      "-> if our_alg:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/nkotelevskii/github/corrected_l2hmc/l2hmc_pytorch/l2hmc/utils/sampler_pt.py(41)propose()\n",
      "-> if do_mh_step:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/nkotelevskii/github/corrected_l2hmc/l2hmc_pytorch/l2hmc/utils/sampler_pt.py(42)propose()\n",
      "-> new_Lx, new_log_px, new_log_jac = tf_accept(x=x, Lx=Lx, log_px=log_px, device=device,\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/nkotelevskii/github/corrected_l2hmc/l2hmc_pytorch/l2hmc/utils/sampler_pt.py(43)propose()\n",
      "-> our_alg=our_alg, use_barker=use_barker, log_jac=log_jac)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> /home/nkotelevskii/github/corrected_l2hmc/l2hmc_pytorch/l2hmc/utils/sampler_pt.py(54)tf_accept()\n",
      "-> def tf_accept(x, Lx, log_px, device='cpu', our_alg=False, use_barker=False, log_jac=None):\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/nkotelevskii/github/corrected_l2hmc/l2hmc_pytorch/l2hmc/utils/sampler_pt.py(55)tf_accept()\n",
      "-> if our_alg:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/nkotelevskii/github/corrected_l2hmc/l2hmc_pytorch/l2hmc/utils/sampler_pt.py(56)tf_accept()\n",
      "-> if use_barker:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/nkotelevskii/github/corrected_l2hmc/l2hmc_pytorch/l2hmc/utils/sampler_pt.py(58)tf_accept()\n",
      "-> logprobs = torch.log(torch.tensor(np.random.rand(*list(log_px[0].shape)), device=device,\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/nkotelevskii/github/corrected_l2hmc/l2hmc_pytorch/l2hmc/utils/sampler_pt.py(59)tf_accept()\n",
      "-> dtype=torchType))\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/nkotelevskii/github/corrected_l2hmc/l2hmc_pytorch/l2hmc/utils/sampler_pt.py(60)tf_accept()\n",
      "-> mask = logprobs <= log_px[0]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  logprobs.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([300])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  l\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 55  \t    if our_alg:\n",
      " 56  \t        if use_barker:\n",
      " 57  \t            # pdb.set_trace()\n",
      " 58  \t            logprobs = torch.log(torch.tensor(np.random.rand(*list(log_px[0].shape)), device=device,\n",
      " 59  \t                                          dtype=torchType))\n",
      " 60  ->\t            mask = logprobs <= log_px[0]\n",
      " 61  \t            new_log_px = torch.where(mask, log_px[0], -log_px[1])\n",
      " 62  \t            new_log_jac = torch.where(mask, log_jac, torch.zeros_like(log_jac))\n",
      " 63  \t            mask = mask[:, None]\n",
      " 64  \t        else:\n",
      " 65  \t            logprobs = torch.log(torch.tensor(np.random.rand(*list(log_px.shape)), device=device,\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/nkotelevskii/github/corrected_l2hmc/l2hmc_pytorch/l2hmc/utils/sampler_pt.py(61)tf_accept()\n",
      "-> new_log_px = torch.where(mask, log_px[0], -log_px[1])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  mask[:10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([False, False, False, False, False,  True, False, False, False, False],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/nkotelevskii/github/corrected_l2hmc/l2hmc_pytorch/l2hmc/utils/sampler_pt.py(62)tf_accept()\n",
      "-> new_log_jac = torch.where(mask, log_jac, torch.zeros_like(log_jac))\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  log_px[0][:10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-92.1533,  -6.9554, -96.6897, -38.8652, -36.4158,  -0.1309,  -4.6488,\n",
      "         -6.2612, -87.0645,  -5.2690], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  -log_px[1][:10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0000e+00, -9.5393e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
      "        -2.0979e+00, -9.6188e-03, -1.9108e-03, -0.0000e+00, -5.1619e-03],\n",
      "       device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  new_log_px[:10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0000, -0.0010, -0.0000, -0.0000, -0.0000, -0.1309, -0.0096, -0.0019,\n",
      "        -0.0000, -0.0052], device='cuda:0', grad_fn=<SliceBackward>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  log_jac.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([300])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  log_jac[:10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0850, -0.1893, -0.3766,  0.7350, -0.1303, -0.2214,  0.0091,  0.0363,\n",
      "        -0.3706, -0.1027], device='cuda:0', grad_fn=<SliceBackward>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  new_log_jac[:10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** NameError: name 'new_log_jac' is not defined\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/nkotelevskii/github/corrected_l2hmc/l2hmc_pytorch/l2hmc/utils/sampler_pt.py(63)tf_accept()\n",
      "-> mask = mask[:, None]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  new_log_jac[:10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.2214,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000], device='cuda:0', grad_fn=<SliceBackward>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/nkotelevskii/github/corrected_l2hmc/l2hmc_pytorch/l2hmc/utils/sampler_pt.py(71)tf_accept()\n",
      "-> mask_cat = torch.cat([mask, mask], dim=-1)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/nkotelevskii/github/corrected_l2hmc/l2hmc_pytorch/l2hmc/utils/sampler_pt.py(72)tf_accept()\n",
      "-> new_Lx = torch.where(mask_cat, Lx, x)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  mask_cat.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([300, 2])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/nkotelevskii/github/corrected_l2hmc/l2hmc_pytorch/l2hmc/utils/sampler_pt.py(73)tf_accept()\n",
      "-> return new_Lx, new_log_px, new_log_jac\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  Lx[:10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8069, -2.7891],\n",
      "        [-1.7364, -1.2934],\n",
      "        [-1.7617, -3.2222],\n",
      "        [-0.4273, -0.7957],\n",
      "        [-1.1723, -1.6859],\n",
      "        [ 2.5052, -0.9343],\n",
      "        [ 1.4962, -0.1979],\n",
      "        [ 1.5864, -0.8012],\n",
      "        [-1.4952, -2.9751],\n",
      "        [ 1.4499, -0.6795]], device='cuda:0', grad_fn=<SliceBackward>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  x[:10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8437, -0.1017],\n",
      "        [-1.2963, -0.6263],\n",
      "        [-0.3385,  0.2929],\n",
      "        [-0.4833,  0.4976],\n",
      "        [-1.4201, -0.0370],\n",
      "        [ 1.6005, -1.1276],\n",
      "        [ 0.5470, -0.2278],\n",
      "        [ 0.3479, -0.8552],\n",
      "        [-0.1601,  0.9624],\n",
      "        [ 0.6798,  0.5042]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  new_Lx[:10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8437, -0.1017],\n",
      "        [-1.2963, -0.6263],\n",
      "        [-0.3385,  0.2929],\n",
      "        [-0.4833,  0.4976],\n",
      "        [-1.4201, -0.0370],\n",
      "        [ 2.5052, -0.9343],\n",
      "        [ 0.5470, -0.2278],\n",
      "        [ 0.3479, -0.8552],\n",
      "        [-0.1601,  0.9624],\n",
      "        [ 0.6798,  0.5042]], device='cuda:0', grad_fn=<SliceBackward>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "> /home/nkotelevskii/github/corrected_l2hmc/l2hmc_pytorch/l2hmc/utils/sampler_pt.py(73)tf_accept()->(tensor([[-8.4...hereBackward>), tensor([-0.00...hereBackward>), tensor([ 0.00...hereBackward>))\n",
      "-> return new_Lx, new_log_px, new_log_jac\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/nkotelevskii/github/corrected_l2hmc/l2hmc_pytorch/l2hmc/utils/sampler_pt.py(44)propose()\n",
      "-> log_jac = new_log_jac\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/nkotelevskii/github/corrected_l2hmc/l2hmc_pytorch/l2hmc/utils/sampler_pt.py(45)propose()\n",
      "-> log_px = new_log_px\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/nkotelevskii/github/corrected_l2hmc/l2hmc_pytorch/l2hmc/utils/sampler_pt.py(46)propose()\n",
      "-> outputs.append(new_Lx)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/nkotelevskii/github/corrected_l2hmc/l2hmc_pytorch/l2hmc/utils/sampler_pt.py(51)propose()\n",
      "-> return Lx, Lv, log_px, outputs, log_jac  # new coordinates, new momenta, new acceptance probability, outputs for coodinates, log_jac\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "> /home/nkotelevskii/github/corrected_l2hmc/l2hmc_pytorch/l2hmc/utils/sampler_pt.py(51)propose()->(tensor([[-8.0...AddBackward0>), tensor([[ -7....AddBackward0>), tensor([-0.00...hereBackward>), [tensor([[-8.4...hereBackward>)], tensor([ 0.00...hereBackward>))\n",
      "-> return Lx, Lv, log_px, outputs, log_jac  # new coordinates, new momenta, new acceptance probability, outputs for coodinates, log_jac\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-10-8bc312febd33>(29)<module>()\n",
      "-> coeff = torch.sigmoid(autoregressive_coeff_logit)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-10-8bc312febd33>(30)<module>()\n",
      "-> p_new = p_prop * coeff + torch.sqrt(1. - coeff**2) * u\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  p_new\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5373, -0.6346],\n",
      "        [-1.2857, -0.7577],\n",
      "        [ 0.9380,  0.4283],\n",
      "        [ 2.8130,  0.4589],\n",
      "        [-0.4191, -0.2773],\n",
      "        [-1.4614,  0.1152],\n",
      "        [ 0.3507, -1.2048],\n",
      "        [-0.3503,  1.3801],\n",
      "        [ 0.5720,  2.5138],\n",
      "        [ 0.7335,  1.5834],\n",
      "        [-1.6687,  0.7262],\n",
      "        [-0.8459, -1.5621],\n",
      "        [ 0.1469,  0.6691],\n",
      "        [-0.6411,  0.3854],\n",
      "        [ 0.9056, -0.2388],\n",
      "        [ 1.9503, -1.5224],\n",
      "        [ 0.2225,  0.2395],\n",
      "        [-0.5865,  0.1057],\n",
      "        [ 0.7131, -0.9151],\n",
      "        [ 0.4243, -1.1558],\n",
      "        [-0.7882, -1.2896],\n",
      "        [ 0.2389, -0.3587],\n",
      "        [-0.8531, -0.2255],\n",
      "        [ 0.6943,  0.0243],\n",
      "        [-0.8485,  0.0998],\n",
      "        [-0.1987,  1.1809],\n",
      "        [ 1.4606, -0.0173],\n",
      "        [-0.0888, -0.9267],\n",
      "        [ 0.2274,  0.0955],\n",
      "        [-0.9823,  1.2160],\n",
      "        [ 1.4834, -2.2613],\n",
      "        [-0.8393, -0.9226],\n",
      "        [ 0.6861, -1.6364],\n",
      "        [ 0.2757,  0.3287],\n",
      "        [-0.5985,  0.5172],\n",
      "        [-0.2242,  0.8260],\n",
      "        [-1.4551,  0.9772],\n",
      "        [-0.0233, -1.2164],\n",
      "        [ 0.7532,  1.0875],\n",
      "        [-0.2673,  1.4616],\n",
      "        [-1.7521, -1.4085],\n",
      "        [-2.4362,  1.7718],\n",
      "        [ 0.6076,  1.4615],\n",
      "        [ 0.8244,  0.5337],\n",
      "        [ 0.6099, -2.0030],\n",
      "        [-0.4649, -0.5729],\n",
      "        [ 1.2769, -1.4303],\n",
      "        [ 1.4338, -1.3943],\n",
      "        [-0.2491, -0.1135],\n",
      "        [ 0.1050, -0.3420],\n",
      "        [-0.7998,  0.4640],\n",
      "        [-0.5014,  0.1609],\n",
      "        [-0.2769, -0.4528],\n",
      "        [ 0.4608,  1.3941],\n",
      "        [-0.3163, -0.0658],\n",
      "        [-0.4157, -0.1829],\n",
      "        [-0.9026, -0.3604],\n",
      "        [-1.3288,  2.4757],\n",
      "        [-0.6698, -0.3027],\n",
      "        [-0.6980,  1.1488],\n",
      "        [ 1.4397,  0.2625],\n",
      "        [ 1.8440,  0.1152],\n",
      "        [-0.5549, -0.0916],\n",
      "        [ 0.7699, -0.1704],\n",
      "        [-0.6228,  0.5953],\n",
      "        [-0.3497,  0.0057],\n",
      "        [ 0.6657,  0.9353],\n",
      "        [ 0.7935,  0.4295],\n",
      "        [ 2.4976, -0.8142],\n",
      "        [-1.2097,  0.0661],\n",
      "        [-1.0794,  1.4810],\n",
      "        [-1.7979,  1.7453],\n",
      "        [ 0.3908,  1.6960],\n",
      "        [ 0.2082,  0.8830],\n",
      "        [-1.2475, -0.9248],\n",
      "        [ 1.3780,  1.9460],\n",
      "        [-0.0194,  0.4734],\n",
      "        [ 0.3502,  1.3235],\n",
      "        [ 0.5700,  1.6945],\n",
      "        [-2.7747, -0.6916],\n",
      "        [-2.4573, -0.7634],\n",
      "        [-2.1025, -0.7810],\n",
      "        [-1.3657, -1.1805],\n",
      "        [ 1.4528,  0.9120],\n",
      "        [-0.8502, -1.9455],\n",
      "        [-0.4365,  0.1267],\n",
      "        [ 1.5653, -0.4305],\n",
      "        [-0.4248,  1.7306],\n",
      "        [ 0.3013,  0.0384],\n",
      "        [ 0.5934, -1.3736],\n",
      "        [ 0.4377, -0.1810],\n",
      "        [ 2.3444, -0.3538],\n",
      "        [ 1.0972,  0.7100],\n",
      "        [-0.7563, -0.5910],\n",
      "        [-0.2345, -1.1502],\n",
      "        [ 0.8817, -0.8009],\n",
      "        [-0.1066, -0.3445],\n",
      "        [ 0.3837, -0.4647],\n",
      "        [ 0.4388,  0.2428],\n",
      "        [-1.5223,  1.5758],\n",
      "        [-0.4144, -0.5437],\n",
      "        [ 0.2045, -1.6944],\n",
      "        [ 0.9425,  0.0383],\n",
      "        [ 0.2698, -0.4470],\n",
      "        [ 0.1170, -0.1253],\n",
      "        [ 0.3359, -0.0050],\n",
      "        [ 0.1363,  0.1193],\n",
      "        [-0.7690,  0.7275],\n",
      "        [ 2.1447,  0.5161],\n",
      "        [ 0.6745, -0.2744],\n",
      "        [-0.7103, -0.2529],\n",
      "        [ 1.9267,  0.2774],\n",
      "        [ 0.3578,  1.0029],\n",
      "        [-1.9655,  1.3440],\n",
      "        [ 0.5997, -0.9007],\n",
      "        [ 1.3896,  0.0565],\n",
      "        [ 0.4632, -0.6332],\n",
      "        [-0.2641, -0.6415],\n",
      "        [-0.9570, -0.5848],\n",
      "        [-0.4881, -0.2702],\n",
      "        [ 0.9927, -1.4274],\n",
      "        [-0.4263,  0.3076],\n",
      "        [-2.0743, -0.5688],\n",
      "        [-0.0575, -0.8523],\n",
      "        [-1.0832, -0.5086],\n",
      "        [-0.5392, -0.1023],\n",
      "        [-0.4680,  1.2813],\n",
      "        [ 1.3106, -1.2018],\n",
      "        [-0.4940,  1.2391],\n",
      "        [-0.0162, -1.9504],\n",
      "        [-0.6494,  0.0588],\n",
      "        [-0.4335, -0.0874],\n",
      "        [ 0.9903, -0.7426],\n",
      "        [ 0.2577,  1.3883],\n",
      "        [-0.2418, -0.1011],\n",
      "        [-0.1381,  0.1990],\n",
      "        [-0.3604,  1.1689],\n",
      "        [-0.4302, -0.0838],\n",
      "        [-1.9288, -0.6506],\n",
      "        [-0.2379, -0.2345],\n",
      "        [ 0.7699,  1.2994],\n",
      "        [-0.0577,  0.5041],\n",
      "        [ 0.3654,  1.1426],\n",
      "        [-0.0285, -0.2831],\n",
      "        [ 1.2724,  0.1655],\n",
      "        [ 1.0064,  1.1734],\n",
      "        [-0.3098,  0.0847],\n",
      "        [-0.1654, -1.3580],\n",
      "        [ 1.0312,  0.0450],\n",
      "        [-2.0306, -0.4650],\n",
      "        [-0.9916, -3.1583],\n",
      "        [ 1.0646, -0.0703],\n",
      "        [-0.2245,  1.3213],\n",
      "        [-0.3604, -0.4610],\n",
      "        [ 0.0642, -0.4644],\n",
      "        [-0.3655, -0.5680],\n",
      "        [-0.4559,  0.6977],\n",
      "        [ 0.4808,  1.5742],\n",
      "        [-0.1541,  0.2143],\n",
      "        [ 1.4602,  0.2433],\n",
      "        [ 1.2475, -0.2719],\n",
      "        [-0.0801, -1.6689],\n",
      "        [ 0.9367, -1.3282],\n",
      "        [-1.5663, -0.8843],\n",
      "        [-0.7027,  0.8047],\n",
      "        [ 0.1781,  1.5248],\n",
      "        [ 0.2052, -1.4484],\n",
      "        [-0.2459,  0.9804],\n",
      "        [-1.0446, -1.7921],\n",
      "        [-1.6344, -1.4400],\n",
      "        [ 0.7280, -0.3750],\n",
      "        [ 0.7811,  0.6170],\n",
      "        [ 0.4974,  0.4940],\n",
      "        [-0.4081, -1.4470],\n",
      "        [ 1.3535, -0.9021],\n",
      "        [-2.2345, -1.1627],\n",
      "        [ 0.0386, -0.6569],\n",
      "        [ 1.1258, -0.8096],\n",
      "        [-1.3997, -0.0342],\n",
      "        [-1.2156, -1.2062],\n",
      "        [ 0.8466, -0.9454],\n",
      "        [ 0.6678,  0.7397],\n",
      "        [-1.4256, -1.4693],\n",
      "        [-0.3379,  0.9334],\n",
      "        [-0.0255, -0.5238],\n",
      "        [-1.1522,  0.3275],\n",
      "        [-0.3570, -1.6313],\n",
      "        [-0.4573,  0.0789],\n",
      "        [ 0.8394,  1.4461],\n",
      "        [-1.1094,  1.2819],\n",
      "        [ 0.0383,  1.1961],\n",
      "        [ 0.2204,  2.0339],\n",
      "        [ 0.0640,  0.0746],\n",
      "        [-1.1299, -0.6940],\n",
      "        [ 0.5179,  0.7409],\n",
      "        [ 1.0280, -0.1532],\n",
      "        [ 0.9832,  1.1576],\n",
      "        [-1.3988, -1.0851],\n",
      "        [-2.6011,  0.5389],\n",
      "        [-2.0326,  0.5703],\n",
      "        [ 0.7591, -0.6807],\n",
      "        [ 0.5421,  0.1631],\n",
      "        [ 1.1911, -0.2298],\n",
      "        [ 0.8289, -0.8671],\n",
      "        [ 2.1812, -0.0112],\n",
      "        [ 0.7507, -0.1600],\n",
      "        [-0.1332, -0.3657],\n",
      "        [ 1.0967,  1.1156],\n",
      "        [ 0.7632,  2.3509],\n",
      "        [-0.2493,  0.1688],\n",
      "        [ 0.3221,  0.3187],\n",
      "        [-1.0269, -0.0315],\n",
      "        [ 0.1350, -0.5807],\n",
      "        [-0.0843,  1.1567],\n",
      "        [ 1.2405,  0.3233],\n",
      "        [-1.2244,  1.0844],\n",
      "        [ 0.1694, -0.2273],\n",
      "        [ 0.7826,  0.6220],\n",
      "        [ 0.9171,  0.1071],\n",
      "        [ 0.9480,  0.1858],\n",
      "        [ 0.0672, -0.7658],\n",
      "        [-0.5549,  0.2647],\n",
      "        [-1.0614, -0.5948],\n",
      "        [-0.4845, -0.9633],\n",
      "        [-1.4432, -0.7146],\n",
      "        [ 2.1708,  0.7243],\n",
      "        [-1.4240, -0.6988],\n",
      "        [-0.1168, -0.8027],\n",
      "        [-0.3704,  0.8064],\n",
      "        [-1.0569, -0.2527],\n",
      "        [ 0.2934, -0.2969],\n",
      "        [-0.6251,  2.4864],\n",
      "        [-0.0823,  0.2350],\n",
      "        [-2.2795,  0.9415],\n",
      "        [ 0.0260,  0.9235],\n",
      "        [ 1.5824,  0.6180],\n",
      "        [ 0.6042, -0.6694],\n",
      "        [-0.6555, -0.1125],\n",
      "        [-0.6608, -0.2496],\n",
      "        [-0.7550,  0.2103],\n",
      "        [-0.9944,  1.8335],\n",
      "        [ 2.8847,  2.4320],\n",
      "        [-1.7464,  1.0737],\n",
      "        [ 1.3240, -1.1414],\n",
      "        [ 0.5694,  0.0934],\n",
      "        [ 0.3386,  0.1903],\n",
      "        [ 1.1744, -1.8274],\n",
      "        [-0.4696, -0.3797],\n",
      "        [-0.3114,  1.1516],\n",
      "        [-0.4830,  0.0069],\n",
      "        [ 0.8751,  0.8368],\n",
      "        [ 0.6600,  0.3226],\n",
      "        [-1.5380, -0.0895],\n",
      "        [ 0.9838, -0.8299],\n",
      "        [-0.5839,  0.8745],\n",
      "        [ 2.3982,  1.5859],\n",
      "        [ 0.1963, -0.3039],\n",
      "        [-0.9219, -1.8029],\n",
      "        [-0.4656, -1.9264],\n",
      "        [-0.2345,  0.7541],\n",
      "        [-1.2412, -2.9775],\n",
      "        [ 1.0790,  0.7718],\n",
      "        [ 1.2663,  0.2513],\n",
      "        [ 0.1110, -1.3682],\n",
      "        [-0.3875,  2.6164],\n",
      "        [ 1.1889,  0.4185],\n",
      "        [ 0.7606, -1.7401],\n",
      "        [-1.7175, -0.2043],\n",
      "        [ 0.6526,  0.3955],\n",
      "        [ 1.6676, -0.9722],\n",
      "        [-0.6800, -0.2172],\n",
      "        [-0.5623,  3.1251],\n",
      "        [-0.4620, -0.2917],\n",
      "        [-0.9644, -0.7973],\n",
      "        [ 1.9770, -0.3066],\n",
      "        [ 0.9460, -0.2286],\n",
      "        [ 2.3174,  2.2063],\n",
      "        [-2.3518,  0.1231],\n",
      "        [ 0.3107,  2.4889],\n",
      "        [-0.6961, -0.5810],\n",
      "        [ 1.4246,  0.4637],\n",
      "        [-0.5647, -1.9594],\n",
      "        [-0.7759,  1.0271],\n",
      "        [ 0.6022, -1.3984],\n",
      "        [-2.4326,  0.1637],\n",
      "        [ 0.2157,  0.8433],\n",
      "        [ 1.4513,  0.2681],\n",
      "        [ 0.6091,  0.8099],\n",
      "        [ 0.3810,  0.2406],\n",
      "        [-0.7050, -0.5223],\n",
      "        [ 0.2306, -1.7148],\n",
      "        [-0.0647, -0.0389],\n",
      "        [-0.0385, -0.0397],\n",
      "        [ 1.1165, -0.0909],\n",
      "        [-0.7168, -0.2411],\n",
      "        [ 1.2568, -0.3770],\n",
      "        [-0.0909,  0.4455],\n",
      "        [-1.1762, -0.4113],\n",
      "        [-0.9808,  0.8888],\n",
      "        [ 0.1222, -0.2950]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-10-8bc312febd33>(31)<module>()\n",
      "-> z_new = z_new[0]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  p_new\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-4.4957e+00, -5.7144e+00],\n",
      "        [ 8.1543e-01, -7.4612e-01],\n",
      "        [ 4.4884e+00,  2.5655e+00],\n",
      "        [-3.3138e+00, -3.9220e+00],\n",
      "        [-3.4651e+00, -1.2867e+00],\n",
      "        [ 5.0981e-01, -6.1823e-01],\n",
      "        [-3.2185e+00,  2.4771e+00],\n",
      "        [-4.1787e+00,  1.1114e+00],\n",
      "        [ 4.4634e+00,  1.2013e+00],\n",
      "        [-3.7353e+00,  1.3688e+00],\n",
      "        [ 3.2807e+00,  2.6924e+00],\n",
      "        [ 2.1889e+00, -7.2045e-01],\n",
      "        [-5.5620e-01,  1.8000e-01],\n",
      "        [-1.4341e+00,  3.7603e+00],\n",
      "        [ 6.3928e+00,  2.5559e+00],\n",
      "        [ 6.3083e+00,  1.3518e+00],\n",
      "        [ 1.3804e+00, -5.2327e+00],\n",
      "        [-1.9514e+00, -2.5069e+00],\n",
      "        [ 2.0115e+00, -1.8626e-01],\n",
      "        [ 2.3921e+00,  4.3547e-01],\n",
      "        [ 1.8180e+00, -2.4553e+00],\n",
      "        [ 8.8845e-01, -2.7394e+00],\n",
      "        [ 5.8288e+00,  1.6886e+00],\n",
      "        [-2.7465e-01, -6.2795e-01],\n",
      "        [-4.1951e+00, -3.7685e+00],\n",
      "        [ 3.4269e+00,  1.9851e+00],\n",
      "        [-4.0754e-01, -3.0048e+00],\n",
      "        [ 4.3806e+00,  3.3627e+00],\n",
      "        [-2.7874e+00, -3.3526e+00],\n",
      "        [ 5.7614e-01,  2.4356e+00],\n",
      "        [ 7.6635e+00, -5.8833e-01],\n",
      "        [ 2.2898e+00, -1.5462e+00],\n",
      "        [ 1.6127e+00, -1.1414e+00],\n",
      "        [ 6.0613e+00,  2.2734e+00],\n",
      "        [ 6.5098e+00,  2.0480e+00],\n",
      "        [ 1.2078e-01,  5.3867e-01],\n",
      "        [-2.8084e+00, -4.4341e-01],\n",
      "        [ 4.8861e+00, -6.1169e-01],\n",
      "        [ 3.6314e+00,  1.4924e+00],\n",
      "        [-1.8689e+00, -1.7479e+00],\n",
      "        [ 3.4353e+00,  1.4032e+00],\n",
      "        [ 1.3510e-01,  1.4318e-01],\n",
      "        [ 2.2619e+00, -1.9887e+00],\n",
      "        [ 3.0347e+00,  4.2852e+00],\n",
      "        [-3.3717e+00,  1.1300e+00],\n",
      "        [-3.2504e+00,  2.1355e-01],\n",
      "        [ 5.5933e+00, -7.0155e-03],\n",
      "        [ 1.8871e+00, -5.7180e-01],\n",
      "        [-1.4711e+00,  2.5335e+00],\n",
      "        [ 2.8880e+00, -3.4841e-01],\n",
      "        [ 2.9374e-01, -2.7659e+00],\n",
      "        [-3.2071e+00, -1.4824e+00],\n",
      "        [-5.0488e+00, -4.4489e+00],\n",
      "        [-4.3138e+00, -7.6515e-01],\n",
      "        [ 1.5479e+00, -2.0214e+00],\n",
      "        [ 3.7252e+00,  2.3245e+00],\n",
      "        [-4.0096e-01,  1.9772e+00],\n",
      "        [ 2.7747e+00,  2.0711e+00],\n",
      "        [ 4.3410e+00,  3.4863e-01],\n",
      "        [ 1.8273e+00, -2.8585e+00],\n",
      "        [ 2.4029e+00,  2.6590e+00],\n",
      "        [-2.9141e+00,  1.4681e+00],\n",
      "        [ 5.1648e-02, -1.2228e-01],\n",
      "        [-6.8371e-02,  2.8814e+00],\n",
      "        [ 2.5005e+00,  2.6461e-01],\n",
      "        [ 2.7738e+00,  1.4976e+00],\n",
      "        [-2.8794e-01, -1.1515e-01],\n",
      "        [-4.6013e+00, -5.1533e+00],\n",
      "        [-2.5076e+00, -5.2630e+00],\n",
      "        [-2.0471e+00, -4.3146e+00],\n",
      "        [-2.0900e+00,  3.5333e-01],\n",
      "        [ 3.5688e+00,  1.4547e+00],\n",
      "        [ 3.6986e+00,  1.9263e+00],\n",
      "        [ 5.8582e+00,  1.1197e+00],\n",
      "        [ 4.9253e-01, -1.8035e+00],\n",
      "        [-3.2259e+00,  1.1037e+00],\n",
      "        [-3.0764e+00, -2.2841e-01],\n",
      "        [-3.0223e+00, -1.5955e+00],\n",
      "        [ 9.8823e-01,  3.7488e-01],\n",
      "        [ 5.9307e+00,  2.2846e+00],\n",
      "        [-2.8500e+00, -7.8985e-01],\n",
      "        [-2.1607e+00, -3.4183e+00],\n",
      "        [-4.9166e+00, -4.2760e+00],\n",
      "        [ 2.1573e+00, -2.4851e+00],\n",
      "        [-2.6608e+00, -3.3019e+00],\n",
      "        [-4.0643e+00, -4.0444e+00],\n",
      "        [ 5.9277e+00,  1.2320e+00],\n",
      "        [-4.7278e+00, -5.0049e+00],\n",
      "        [ 1.1559e+00, -2.3533e+00],\n",
      "        [ 4.8020e+00,  1.1607e+00],\n",
      "        [ 6.0213e-01, -2.0739e+00],\n",
      "        [ 1.7509e+00,  1.7390e+00],\n",
      "        [ 3.6259e+00,  2.9351e+00],\n",
      "        [ 6.6351e+00,  1.9571e+00],\n",
      "        [-1.5694e+00, -1.3923e-01],\n",
      "        [ 5.1220e+00,  2.7544e+00],\n",
      "        [-2.6623e+00, -2.5167e+00],\n",
      "        [ 1.6820e+00, -2.4118e+00],\n",
      "        [ 1.9369e+00, -3.4734e+00],\n",
      "        [-2.7940e+00, -4.5268e+00],\n",
      "        [-3.7650e+00, -4.0343e+00],\n",
      "        [ 1.8149e+00, -3.0281e+00],\n",
      "        [-2.3192e+00, -4.3601e+00],\n",
      "        [ 1.3840e+00,  8.2933e-01],\n",
      "        [ 2.0027e+00,  2.0345e-01],\n",
      "        [ 2.3041e+00, -1.3892e+00],\n",
      "        [-3.5866e+00, -3.1859e+00],\n",
      "        [-4.5786e+00, -1.8937e+00],\n",
      "        [-7.5723e-01, -6.4317e-01],\n",
      "        [-4.7744e+00, -3.2662e+00],\n",
      "        [ 3.5614e+00,  1.4387e+00],\n",
      "        [-1.6402e+00, -9.1073e+00],\n",
      "        [ 2.4390e+00,  1.4672e+00],\n",
      "        [ 3.4247e+00,  1.7101e+00],\n",
      "        [ 1.3990e+00, -3.5193e+00],\n",
      "        [ 5.6254e+00,  2.7219e-01],\n",
      "        [ 6.0523e+00,  2.3267e+00],\n",
      "        [ 4.5724e-01,  4.0181e-01],\n",
      "        [-2.9375e+00,  1.0386e+00],\n",
      "        [ 4.8767e+00,  1.1896e+00],\n",
      "        [-6.1531e-01,  1.4176e+00],\n",
      "        [-3.4990e+00, -4.4274e+00],\n",
      "        [-3.6648e+00, -2.4884e+00],\n",
      "        [-5.0597e+00, -4.9158e+00],\n",
      "        [-2.1454e+00,  3.4671e+00],\n",
      "        [ 5.8530e-01, -7.9200e-03],\n",
      "        [-3.4749e+00, -2.0667e+00],\n",
      "        [ 3.1924e-02,  4.2482e+00],\n",
      "        [ 3.7686e+00,  2.6249e+00],\n",
      "        [-2.5952e+00, -2.9692e+00],\n",
      "        [-4.5908e-01, -3.5540e+00],\n",
      "        [-3.5017e+00, -5.7051e+00],\n",
      "        [ 4.7012e+00,  1.3270e+00],\n",
      "        [-2.4004e+00, -1.8055e-01],\n",
      "        [-2.7564e+00,  2.3640e+00],\n",
      "        [-2.9783e+00,  1.3253e+00],\n",
      "        [-4.2725e+00, -2.2500e+00],\n",
      "        [ 4.2146e+00,  1.2461e+00],\n",
      "        [ 2.9455e+00,  1.1073e+00],\n",
      "        [ 2.0563e+00,  4.1108e+00],\n",
      "        [-9.2296e-01, -1.7087e+00],\n",
      "        [-3.4301e+00, -1.4864e+00],\n",
      "        [ 9.1626e-01, -2.3670e+00],\n",
      "        [-5.7584e+00, -3.1206e+00],\n",
      "        [ 1.1372e+00, -1.4343e+00],\n",
      "        [ 1.2886e+00, -5.6540e+00],\n",
      "        [ 5.8654e+00,  1.9412e+00],\n",
      "        [-8.1013e-01, -1.9502e+00],\n",
      "        [-4.4696e-01,  6.9395e-01],\n",
      "        [-2.2622e+00,  7.6031e-02],\n",
      "        [ 4.1825e+00,  4.0050e-01],\n",
      "        [ 1.1230e+00, -7.1593e+00],\n",
      "        [-5.0348e+00,  2.7618e+00],\n",
      "        [-3.1816e+00, -4.8761e+00],\n",
      "        [-1.8482e+00, -5.9918e-01],\n",
      "        [-2.0152e+00, -2.1962e+00],\n",
      "        [ 7.5504e-01, -4.6826e+00],\n",
      "        [-3.6199e+00, -1.9863e+00],\n",
      "        [ 5.7155e+00,  2.8436e+00],\n",
      "        [ 2.2305e+00,  1.8483e+00],\n",
      "        [-1.1487e+00,  7.3210e-01],\n",
      "        [-2.9601e+00,  1.4745e+00],\n",
      "        [-7.9946e-02,  1.0657e-02],\n",
      "        [-2.4880e+00,  7.2334e-01],\n",
      "        [-3.9703e+00, -1.7034e+00],\n",
      "        [ 1.4526e+00,  7.9311e-01],\n",
      "        [ 2.0725e-01, -1.5281e+00],\n",
      "        [-3.4147e+00, -2.0070e+00],\n",
      "        [-4.7595e+00, -6.3435e+00],\n",
      "        [ 1.1725e+00,  5.4634e-01],\n",
      "        [ 4.3841e-01, -4.5328e-01],\n",
      "        [-2.2363e+00, -1.4033e+00],\n",
      "        [ 2.1236e+00,  1.0270e+00],\n",
      "        [ 5.6125e-01, -1.4025e+00],\n",
      "        [-8.8404e-01,  1.1268e+00],\n",
      "        [-4.3402e+00, -1.0753e+01],\n",
      "        [-6.8433e-01, -2.1970e+00],\n",
      "        [-1.7517e+00, -2.5263e+00],\n",
      "        [ 6.5837e+00,  2.2041e+00],\n",
      "        [ 1.2340e+00,  1.5597e+00],\n",
      "        [ 1.9805e+00, -1.2031e+00],\n",
      "        [-1.0539e+00, -1.0635e+00],\n",
      "        [-2.6852e+00, -6.1362e-01],\n",
      "        [-3.9249e+00,  7.6587e-01],\n",
      "        [ 2.5159e+00,  8.0868e-01],\n",
      "        [-1.8091e+00, -6.2892e-01],\n",
      "        [ 1.1080e+00, -2.5106e+00],\n",
      "        [ 2.0912e+00, -2.6711e+00],\n",
      "        [ 7.5766e-01,  1.1378e+00],\n",
      "        [ 2.9919e-01, -4.7206e-01],\n",
      "        [-2.7704e+00, -8.7860e-01],\n",
      "        [ 3.5562e-01, -2.5756e+00],\n",
      "        [ 1.0390e+00,  9.0734e-01],\n",
      "        [-1.4449e+00,  2.6497e+00],\n",
      "        [-5.8723e-01, -3.7917e+00],\n",
      "        [-3.9815e+00,  1.6312e+00],\n",
      "        [ 1.6968e+00,  3.4247e+00],\n",
      "        [-1.7786e+00,  1.7477e+00],\n",
      "        [ 1.2181e+00, -2.6357e-01],\n",
      "        [-1.5848e-01, -3.3641e+00],\n",
      "        [ 1.5359e+00,  9.8237e-01],\n",
      "        [-1.2803e+00,  3.1418e+00],\n",
      "        [-1.8714e+00,  1.8639e+00],\n",
      "        [-9.9985e-01,  4.8696e-02],\n",
      "        [ 4.0163e+00,  1.2600e+00],\n",
      "        [ 2.1343e+00,  1.9750e+00],\n",
      "        [ 3.2634e-01, -5.5366e+00],\n",
      "        [ 3.1408e+00,  2.4082e+00],\n",
      "        [-5.3706e+00, -9.0750e-01],\n",
      "        [ 4.7224e-01, -3.9962e-01],\n",
      "        [ 3.2996e-01, -5.9923e+00],\n",
      "        [-4.5095e+00,  1.3161e+00],\n",
      "        [-3.1529e+00,  8.6168e-01],\n",
      "        [ 3.0727e+00,  2.5217e+00],\n",
      "        [-2.9261e+00,  9.3859e-02],\n",
      "        [ 3.3379e+00,  1.0834e+00],\n",
      "        [ 2.7936e+00,  3.0073e+00],\n",
      "        [ 6.4831e+00,  1.9564e+00],\n",
      "        [ 1.8474e+00,  2.2147e+00],\n",
      "        [ 8.7053e-01, -5.9479e-01],\n",
      "        [-4.6043e+00, -5.0431e+00],\n",
      "        [-1.7897e+00,  1.0987e-01],\n",
      "        [-3.2478e+00,  2.0524e+00],\n",
      "        [-3.3405e+00, -1.7282e+00],\n",
      "        [ 1.4970e+00,  2.4383e+00],\n",
      "        [-1.6151e+00, -2.2979e+00],\n",
      "        [ 7.6166e-01,  1.7344e+00],\n",
      "        [ 9.9962e-01,  7.5897e-01],\n",
      "        [ 2.4571e+00,  2.0974e+00],\n",
      "        [-2.6856e+00,  7.0790e-01],\n",
      "        [-3.3024e+00,  3.9882e+00],\n",
      "        [-5.5354e-02, -3.2678e+00],\n",
      "        [-2.3397e+00,  5.5819e+00],\n",
      "        [-1.3429e+00,  3.4010e-01],\n",
      "        [-1.0035e+00,  1.6276e+00],\n",
      "        [-8.4935e-01, -2.6528e+00],\n",
      "        [ 8.5881e-01, -1.7013e+00],\n",
      "        [-2.3494e+00, -3.0871e+00],\n",
      "        [-1.1302e-03, -2.0585e-02],\n",
      "        [-2.6014e+00,  1.1461e+00],\n",
      "        [-8.8611e-02,  7.3722e-01],\n",
      "        [-8.3429e-03, -6.1945e+00],\n",
      "        [-1.3248e+00,  8.0050e-01],\n",
      "        [-4.8532e+00, -4.6930e+00],\n",
      "        [-2.6069e+00,  1.4309e+00],\n",
      "        [-1.4494e+00, -2.7976e+00],\n",
      "        [ 4.4399e+00,  3.0507e-01],\n",
      "        [ 2.6913e-01,  6.0158e-01],\n",
      "        [-4.6796e+00, -1.4636e+00],\n",
      "        [-4.6466e+00,  2.5199e+00],\n",
      "        [-3.1875e+00,  2.4477e-01],\n",
      "        [-1.4742e+00,  1.2717e+00],\n",
      "        [ 4.6326e+00,  1.1756e+00],\n",
      "        [ 5.9339e+00,  2.0219e+00],\n",
      "        [-2.4950e+00, -2.1180e+00],\n",
      "        [ 2.0359e+00,  6.5568e-01],\n",
      "        [-1.8813e+00, -8.9775e-02],\n",
      "        [ 9.3969e-01, -8.3496e-01],\n",
      "        [ 9.6931e-01, -2.2899e+00],\n",
      "        [-3.9396e+00, -2.1613e+00],\n",
      "        [-2.0584e+00, -1.3373e+00],\n",
      "        [-1.0881e+00,  1.4201e+00],\n",
      "        [-1.7136e+00, -3.0507e+00],\n",
      "        [-2.4685e+00,  2.2237e+00],\n",
      "        [ 4.1449e-01, -1.3331e+00],\n",
      "        [ 1.9735e+00,  3.8083e-01],\n",
      "        [ 5.2907e+00,  7.7699e-01],\n",
      "        [-5.1626e+00, -8.7770e-01],\n",
      "        [-1.1008e+00, -2.2441e+00],\n",
      "        [-6.5937e-01, -4.4642e+00],\n",
      "        [ 4.1122e+00,  1.3005e+00],\n",
      "        [-5.7498e-01,  1.5956e+00],\n",
      "        [ 7.0553e-01, -4.2917e+00],\n",
      "        [ 1.7352e+00, -2.8737e-01],\n",
      "        [ 6.1087e+00, -8.7343e-02],\n",
      "        [-2.6961e+00, -2.7744e+00],\n",
      "        [ 5.3652e+00,  1.5966e+00],\n",
      "        [-3.2573e+00,  1.5157e+00],\n",
      "        [-4.5967e-01, -1.5559e+00],\n",
      "        [ 8.0770e-01, -4.1134e-01],\n",
      "        [-6.5943e-01,  7.8433e-01],\n",
      "        [ 3.4316e+00,  1.0832e+00],\n",
      "        [-3.9549e+00, -3.6597e+00],\n",
      "        [ 2.4538e-01, -5.1443e+00],\n",
      "        [ 2.0268e+00,  1.5867e-01],\n",
      "        [ 4.1058e+00,  1.6937e+00],\n",
      "        [ 1.9578e+00, -2.0826e-01],\n",
      "        [ 2.2860e-01,  6.9363e-01],\n",
      "        [ 1.1576e+00, -2.9864e+00],\n",
      "        [-4.1453e+00, -3.0712e+00],\n",
      "        [ 6.6672e+00,  7.1073e-01],\n",
      "        [-2.0732e+00,  9.3822e-02],\n",
      "        [-3.5530e+00,  1.9073e+00],\n",
      "        [-2.8973e-02,  6.4175e-01],\n",
      "        [-5.6229e-01, -2.8669e+00],\n",
      "        [ 4.1526e+00,  3.9378e+00],\n",
      "        [ 8.1430e-01,  1.9446e+00],\n",
      "        [-4.1862e+00, -7.5388e+00],\n",
      "        [-3.5347e+00, -1.2437e+00],\n",
      "        [-4.1707e+00, -2.7063e+00]], device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  l\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 26  \t        pdb.set_trace()\n",
      " 27  \t        _, p_prop, log_alpha, z_new, log_jac = propose(x=z_old, dynamics=dynamics,\n",
      " 28  \t                                                       init_v=p_new, do_mh_step=True, device=device, our_alg=True, use_barker=True)\n",
      " 29  \t        coeff = torch.sigmoid(autoregressive_coeff_logit)\n",
      " 30  \t        p_new = p_prop * coeff + torch.sqrt(1. - coeff**2) * u\n",
      " 31  ->\t        z_new = z_new[0]\n",
      " 32  \t\n",
      " 33  \t        sum_log_alpha = sum_log_alpha + log_alpha\n",
      " 34  \t        sum_log_jacobian = sum_log_jacobian + log_jac + x_dim * torch.log(coeff)\n",
      " 35  \t\n",
      " 36  \t    elbo_full, grad_elbo = compute_loss(z_new=z_new, p_new=p_new, z_old=z_old, p_old=p_old, sum_log_alpha=sum_log_alpha,\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-10-8bc312febd33>(33)<module>()\n",
      "-> sum_log_alpha = sum_log_alpha + log_alpha\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-10-8bc312febd33>(34)<module>()\n",
      "-> sum_log_jacobian = sum_log_jacobian + log_jac + x_dim * torch.log(coeff)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-10-8bc312febd33>(24)<module>()\n",
      "-> for k in range(K):\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  log_jac.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([300])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  x_dim * torch.log(coeff).shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  q\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-8bc312febd33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mp_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp_old\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstd_normal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-8bc312febd33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mp_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp_old\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstd_normal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/condatorch/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/condatorch/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "scheduler = StepLR(optim, step_size=1000, gamma=0.96)\n",
    "std_normal = torch.distributions.Normal(loc=torch.tensor(0., dtype=torch.float32, device=device),\n",
    "                                                scale=torch.tensor(1., dtype=torch.float32, device=device))\n",
    "torch_log_2 = torch.tensor(np.log(2.), device=device, dtype=torch.float32)\n",
    "\n",
    "def compute_loss(z_new, p_new, z_old, p_old, sum_log_alpha, sum_log_jac):\n",
    "    log_p = distribution.get_logdensity(z_new) + std_normal.log_prob(p_new).sum(1)\n",
    "    log_r = -K * torch_log_2\n",
    "    log_m = std_normal.log_prob(z_old).sum(1) + std_normal.log_prob(p_old).sum(1) - sum_log_jac + sum_log_alpha\n",
    "    elbo_full = log_p + log_r - log_m\n",
    "    grad_elbo = torch.mean(elbo_full + elbo_full.detach() * sum_log_alpha)\n",
    "    return elbo_full.detach().mean().item(), grad_elbo\n",
    "\n",
    "for t in tqdm(range(n_batches)):    \n",
    "    z_old = std_normal.sample((n_samples, x_dim))\n",
    "    p_old = std_normal.sample((n_samples, x_dim))\n",
    "    optim.zero_grad()\n",
    "    sum_log_alpha = torch.zeros(z_old.shape[0], dtype=torch.float32, device=device) # for grad log alpha accumulation\n",
    "    sum_log_jacobian = torch.zeros(z_old.shape[0], dtype=torch.float32, device=device) # for log_jacobian accumulation\n",
    "    \n",
    "    z_new = z_old.detach()\n",
    "    p_new = p_old.detach()\n",
    "    \n",
    "    for k in range(K):\n",
    "        u = std_normal.sample(p_new.shape)\n",
    "#         pdb.set_trace()\n",
    "        _, p_prop, log_alpha, z_new, log_jac = propose(x=z_old, dynamics=dynamics,\n",
    "                                                       init_v=p_new, do_mh_step=True, device=device, our_alg=True, use_barker=True)\n",
    "        coeff = torch.sigmoid(autoregressive_coeff_logit)\n",
    "        p_new = p_prop * coeff + torch.sqrt(1. - coeff**2) * u\n",
    "        z_new = z_new[0]\n",
    "        \n",
    "        sum_log_alpha = sum_log_alpha + log_alpha\n",
    "        sum_log_jacobian = sum_log_jacobian + log_jac + x_dim * torch.log(coeff)\n",
    "        \n",
    "    elbo_full, grad_elbo = compute_loss(z_new=z_new, p_new=p_new, z_old=z_old, p_old=p_old, sum_log_alpha=sum_log_alpha,\n",
    "                                        sum_log_jac=sum_log_jacobian)\n",
    "    (-grad_elbo).backward()\n",
    "    optim.step()\n",
    "    scheduler.step()\n",
    "    #     pdb.set_trace()\n",
    "\n",
    "    if t % 100 == 0:\n",
    "        current_lr = None\n",
    "        for param_group in optim.param_groups:\n",
    "            current_lr = param_group['lr']\n",
    "        print ('Step: %d / %d, ELBO: %.2e, LR: %.5f, Autoregressive Coef %.2f' % (t, n_batches, elbo_full, current_lr,\n",
    "                                                                                torch.sigmoid(autoregressive_coeff_logit).cpu().detach().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_of_chains = 200 #2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = torch.tensor(distribution.get_samples(n=n_samples), dtype=torch.float32, device=device)\n",
    "final_samples = []\n",
    "\n",
    "samples_ = samples\n",
    "with torch.no_grad():\n",
    "#     pdb.set_trace()\n",
    "    for t in tqdm(range(length_of_chains)):\n",
    "        final_samples.append(samples_.cpu().numpy())\n",
    "        _, _, _, samples_, _ = propose(samples_, dynamics, do_mh_step=True, device=device)\n",
    "        samples_ = samples_[0].detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L2HMC_samples = np.array(final_samples)\n",
    "with torch.no_grad():\n",
    "    HMC_samples_1 = get_hmc_samples(2, 0.1, distribution.get_energy_function(), steps=length_of_chains, samples=samples, device=device)\n",
    "    HMC_samples_2 = get_hmc_samples(2, 0.15, distribution.get_energy_function(), steps=length_of_chains, samples=samples, device=device)\n",
    "    HMC_samples_3 = get_hmc_samples(2, 0.2, distribution.get_energy_function(), steps=length_of_chains, samples=samples, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L2HMC_samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HMC_samples_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = np.sqrt(np.trace(cov.cpu().detach().numpy()))\n",
    "L2HMC = acl_spectrum(L2HMC_samples, scale=scale)\n",
    "HMC1 = acl_spectrum(HMC_samples_1, scale=scale)\n",
    "HMC2 = acl_spectrum(HMC_samples_2, scale=scale)\n",
    "HMC3 = acl_spectrum(HMC_samples_3, scale=scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_to_plot = np.min([300, length_of_chains - 1])\n",
    "xaxis = 10 * np.arange(points_to_plot)\n",
    "plt.plot(xaxis, L2HMC[:points_to_plot], label='L2HMC')\n",
    "plt.plot(xaxis, HMC1[:points_to_plot], label='HMC $\\epsilon=0.1$')\n",
    "plt.plot(xaxis, HMC2[:points_to_plot], label='HMC $\\epsilon=0.15$')\n",
    "plt.plot(xaxis, HMC3[:points_to_plot], label='HMC $\\epsilon=0.2$')\n",
    "plt.ylabel('Auto-correlation')\n",
    "plt.xlabel('Gradient Computations')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 13\n",
    "\n",
    "points_to_plot = np.min([200, length_of_chains - 1])\n",
    "\n",
    "plt.scatter(S[:points_to_plot, 0], S[:points_to_plot, 1], label='True')\n",
    "plt.plot(L2HMC_samples[:points_to_plot, num, 0], L2HMC_samples[:points_to_plot, num, 1], label='Sampled L2HMC', color='black', marker='o')\n",
    "plt.plot(HMC_samples_2[:points_to_plot, num, 0], HMC_samples_2[:points_to_plot, num, 1], label='Sampled HMC $\\epsilon=0.1$', color='red', marker='s', alpha=0.3)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num = 1\n",
    "plt.plot(L2HMC_samples[:points_to_plot, num, 0], L2HMC_samples[:points_to_plot, num, 1], label='Sampled L2HMC', color='black', marker='o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.notebook_utils_pt import get_hmc_samples, plot_gaussian_contours\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_palette(\"muted\")\n",
    "\n",
    "# Color definition for plots\n",
    "c_l2hmc, c_hmc1, c_hmc2, c_hmc3 = 'blue', 'orange', 'green', 'red'\n",
    "c_true, c_contour = 'purple', '0.75'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6, 3))\n",
    "plot_gaussian_contours(mus, covs, colors=[c_contour, c_contour], x_lims=[-2.8,2.8], y_lims=[-1,1], res=100)\n",
    "plt.plot(HMC_samples_2[:points_to_plot, 1, 0], HMC_samples_2[:points_to_plot, 1, 1], color=c_hmc1, marker='o', alpha=0.6)\n",
    "plt.xlim([-5,5])\n",
    "plt.title('Gaussian Mixture Model Sampling via HMC ($\\epsilon = 0.15$)')\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6, 3))\n",
    "plot_gaussian_contours(mus, covs, colors=[c_contour, c_contour], x_lims=[-2.8,2.8], y_lims=[-1,1])\n",
    "plt.plot(HMC_samples_3[:points_to_plot, 1, 0], HMC_samples_3[:points_to_plot, 1, 1], color=c_hmc2, marker='o', alpha=0.6)\n",
    "plt.title('Gaussian Mixture Model Sampling via HMC ($\\epsilon = 0.2$)')\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Condatorch",
   "language": "python",
   "name": "condatorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
